{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c347b95a",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent Neural Networks (RNNs) sind neben den CNNs eine weitere spezielle Form von Neuronalen Netzen. \n",
    "RNNs werden hauptsächlich für Sequenzen, die in einer festen Reihenfolge angeordnet sind, verwendet. In diesen Fällen ist die Reihenfolge der einzelnen Elemente der Sequenz oft entscheidend für die Interpretation der gesamten Sequenz.\n",
    "\n",
    "Sprachen als klassisches Beispiel bieten sich sofort an. Das liegt daran, dass der Inhalt eines Satzes die Interpretation der einzelnen Wörter beeinflusst. \n",
    "\n",
    "Ein Beispiel:\n",
    "\n",
    "> Ich bin kein Fan von diesem Film.\n",
    "\n",
    "\n",
    "Das Wort \"*Fan*\" hat eine positive Konnotation. Aber das \"*nicht*\" vor dem Wort, dreht die Interpretation um. Das heißt, das Wort \"*Fan*\" sollte im Kontext des gesamten Satzes interpretiert werden. \n",
    "RNNs können aber auch in der Chemie/Pharmazie eingesetzt werden. So eignen sich zum Beispiel Smiles `strings` oder Proteinsequenzen für RNNs. \n",
    "\n",
    " `()` haben einen starken Einfluss darauf, wie einzelne Teile des Smiles interpretiert werden können.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "`CCCC`|`CC(C)C`\n",
    "------|--------\n",
    "<img align=\"center\" src=\"Img/rnn/mol1.png\" width=\"200\"/> | <img  align=\"center\" src=\"Img/rnn/mol2.png\" width=\"200\"/> \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Das allgemeine Konzept eines RNN ist relativ einfach:\n",
    "Wort für Wort (oder auch Zeichen für Zeichen) wird ein Satz (Smiles) durch das Netz geführt. \n",
    "Die Outputlayer wird zunächst komplett ignoriert, aber nachdem ein Wort durch das Netz gelaufen ist, werden die Activations der versteckten Schicht ($h_1$) gespeichert.\n",
    "\n",
    "Anhand des Beispielsatzes \"*Hallo Welt*\" wird dies im Bild erklärt. $h_1$ sind hier die Activations für das Wort \"Hallo\".\n",
    "\n",
    "Im Zusammenhang mit RNNs bezeichnen wir die Activations der Hidden Layer auch als **Hidden State**. $h_1$ ist der Hidden State für das Wort \"*Hallo*\".\n",
    "\n",
    "Als nächstes wird das zweite Wort durch das Netz geschickt. Wir wollen $h_2$ berechnen, aber zu den regulären Activations des Wortes \"Welt\" addieren wir auch die Aktivierungen $h_1$. $h_2$ ist also eine Kombination aus den Activations von \"Welt\", aber auch von \"Hallo\". Das bedeutet, dass das Wort \"Welt\" zusammen mit dem vorangegangenen Wort interpretiert wurde.\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img align=\"center\" src=\"Img/rnn/rnn_1.svg.png\" width=\"200\"/> \n",
    "</div>\n",
    "\n",
    "Hätten wir ein drittes Wort, würde $h_3$ aus den Activations des dritten Wortes und $h_2$ berechnet werden. Und da $h_2$ die Informationen sowohl des zweiten als auch des ersten Wortes enthält, beeinflussen beide Wörter die Interpretation des dritten Wortes.\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img align=\"center\" src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "    \n",
    "*Source: Michael Phi - An illustrated Guide to Recurrent Neural Networks*\n",
    "\n",
    "</div>\n",
    "    \n",
    "Im GIF sehen Sie, dass der Einfluss des Hidden States von \"*What*\" (schwarz), dem ersten Wort, immer geringer wird, je näher wir dem Ende des Satzes kommen. Er hat jedoch immer noch einen Einfluss auf die Interpretation des letzten Wortes.\n",
    "\n",
    "\n",
    "Der Hidden State des letzten Teils des Satzes (\"*?* \"), im Beispiel $O5$ ($h_5$) genannt, ist eine Kombination aus allen vorherigen Hidden States und den Activations von \"*?* \".\n",
    "\n",
    "<div align=\"center\">\n",
    "            \n",
    "<img align=\"center\" src=\"https://ichi.pro/assets/images/max/724/1*yQzlE7JseW32VVU-xlOUvQ.png\">\n",
    "\n",
    "</div>\n",
    "\n",
    "Wir können diesen Hidden State als Input für ein  weiteres Netzwerk verwenden, das seine Vorhersage auf der Grundlage dieses letzten Hidden States macht.\n",
    "\n",
    "Ähnlich wie ein CNN verwendet wird, um ein Bild in einen Vektor umzuwandeln, werden RNNs verwendet, um Sequenzen in Vektoren umzuwandeln.\n",
    "\n",
    "\n",
    "# Datenaufbereitung:\n",
    "\n",
    "Doch bevor wir unser RNN trainieren, müssen wir die Daten in das richtige Format bringen. Buchstaben und Wörter können nicht einfach von einem neuronalen Netz gelesen werden.\n",
    "Wie bei den Bezeichnungen aus dem MNIST-Datensatz (0-9) können wir Wörter oder, im Fall von Smiles, Zeichen \"one-hot\" kodieren. \n",
    "\n",
    "Angenommen wir haben zwei Smiles:\n",
    "\n",
    "`smiles = [\"CCN=C=O\",\"NC(=O)CC(=O)O\"]`\n",
    "\n",
    "Es gibt insgesamt sechs verschiedene Symbole:\n",
    "`C`, `N`, `=`, `O`, `(`, `)` \n",
    "\n",
    "Wir können ein `C` als einen Vektor der Länge 6 darstellen. Dieser hat an der ersten Position eine `1` und sonst nur Nullen. Ein `N` können wir ebenfalls als Vektordarstellen, nur dass wir die `1` um eine Position verschieben.\n",
    "\n",
    "Dies können wir für alle Symbole in den Smiles machen:\n",
    "\n",
    "```python\n",
    "\"C\" = [1,0,0,0,0,0]\n",
    "\"N\" = [0,1,0,0,0,0]\n",
    "\"=\" = [0,0,1,0,0,0]\n",
    "\"O\" = [0,0,0,1,0,0]\n",
    "\"(\" = [0,0,0,0,1,0]\n",
    "\")\" = [0,0,0,0,0,1]\n",
    "```\n",
    "Diese Symbole werden auch oft **Tokens** genannt.\n",
    "Wir können also einen Smiles `string` mithilfe dieser Regeln kodieren. Wir brauchen also pro Smiles eine Matrix:\n",
    "\n",
    "```python\n",
    "\"CCN=C=O\" -> np.array([[1,0,0,0,0,0],\n",
    "                      [1,0,0,0,0,0],\n",
    "                      [0,1,0,0,0,0],\n",
    "                      [0,0,1,0,0,0],\n",
    "                      [1,0,0,0,0,0],\n",
    "                      [0,0,1,0,0,0],\n",
    "                      [0,0,0,1,0,0]])\n",
    "```\n",
    "\n",
    "Der `string`  `\"CCN=C=O\"` wird zu einer Matrix, in der jede Zeile ein Token ist und jede Spalte angibt, welche Symbole dieser Zeile zugeordnet sind.\n",
    "\n",
    "Mit dem folgenden Code können Sie diese Umwandlung automatisieren.\n",
    "Viele Funktionen sind schon von uns vorgeschrieben. Wenn Sie aber trotzdem daran interessiert sind, wie diese Funktionen genau aussehen, finden Sie den Code in `../utils/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69935db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from os.path import exists\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install rdkit==2022.3.4\n",
    "    if exists(\"utils.py\") == False:\n",
    "        !wget https://raw.githubusercontent.com/kochgroup/intro_pharma_ai/main/utils/utils.py\n",
    "    %run utils.py\n",
    "else:\n",
    "    %run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = [\"CCN=C=O\",\"NC(=O)CC(=O)O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9658c3",
   "metadata": {},
   "source": [
    "Zunächst brauchen wir eine Art Wörterbuch, das alle vorkommenden Symbole speichert und ihnen eine Zahl zuweist. Diese Zahl gibt auch an, an welcher Stelle im One-Hot-Vektor die `1` stehen wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = create_dict(smiles)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355072c",
   "metadata": {},
   "source": [
    "Sie sehen, dem `=` wird eine `0` zugewiesen und dem `N` eine `1` und so weiter....\n",
    "\n",
    "Mit der Funktion `tokenize()` kann man die Smiles in eine Zahlenfolge umwandeln. Wir stellen nun die Smiles-`string` mit den Zahlen dar. \n",
    "Der Funktion muss lediglich mitgeteilt werden, welche Smiles kodiert werden sollen und welcher `dictionary` dafür verwendet werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ea9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles = tokenize(smiles,dictionary)\n",
    "tokenized_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f40859",
   "metadata": {},
   "source": [
    "Die Smiles werden nun als eine einfache Zahlenfolge dargestellt.\n",
    "Diese sind jedoch immer noch unterschiedlich lang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4aca32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[len(x) for x in tokenized_smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d3bb5",
   "metadata": {},
   "source": [
    "Der erste Smiles besteht aus 7 Symbolen/Tokens, der andere aus 13. Das ist ein Problem, denn ein RNN erwartet, dass jede Sequenz gleich lang ist. Das ist natürlich nicht immer möglich, denn größere Moleküle haben mehr Symbole als kleinere. \n",
    "Um das Problem zu lösen, *\"padden\"* wir alle Sequenzen auf die Länge des längsten Smiles.\n",
    "Das \"*padden*\" bedeutet, dass wir einen neuen Token zu unserem Wörterbuch hinzufügen: `\"<pad>\"`. Dieses Symbol wird zu jedem Smiles-`string` hinzugefügt, bis sie dieser die gleiche Länge hat wie der längste Smiles. \n",
    "Das `\"<pad>\"` soll dem Netz mitteilen, dass diese Symbole für den eigentlichen Smiles nicht mehr relevant sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a045f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_smiles_length = max([len(x) for x in tokenized_smiles])\n",
    "max_smiles_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf6095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary[\"<pad>\"] = len(dictionary)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b1e90",
   "metadata": {},
   "source": [
    "Jetzt haben wir den Token `<pad>` zu unserem Wörterbuch hinzugefügt. Das Letzte, was wir tun müssen, ist, diesen Token an unseren ersten Smiles `tokenized_smiles[0]` anzuhängen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fehlende_tokens = max_smiles_length-len(tokenized_smiles[0])\n",
    "tokenized_smiles[0] += [dictionary[\"<pad>\"]] * num_fehlende_tokens \n",
    "tokenized_smiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107b894",
   "metadata": {},
   "source": [
    "Jetzt sind beide Smiles gleich lang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(x) for x in tokenized_smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb806be8",
   "metadata": {},
   "source": [
    "Da die Smiles jetzt die gleiche Länge haben, können wir nun die Zahlen in One-Hot kodierte Vektoren umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_length = len(dictionary)\n",
    "print(vocabulary_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf595f",
   "metadata": {},
   "source": [
    "Insgesamt befinden sich 7 Symbole in unserem Wörterbuch.\n",
    "Mit der Funktion `token_to_onehot` werden aus den `tokenized_smiles` Matrizen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d7a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onehot_tokens = token_to_onehot(tokenized_smiles, vocabulary_length)\n",
    "print(onehot_tokens[0])\n",
    "      \n",
    "print(onehot_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce5a92",
   "metadata": {},
   "source": [
    "`onehot_tokens` ist `np.array` mit den Dimensionen  `(2,13,7)` . Die erste Dimension ist die Anzahl der Smiles (`2`). Die zweite Dimension ist die Länge der Sequenzen (`13`). Die dritte Dimension ist die Anzahl der verschiedenen Token (`7`).\n",
    "\n",
    "An sich wären unsere Daten jetzt bereit für ein RNN. Aber anstatt diese One-Hot kodierten Vektoren als Input zu nehmen, verwenden wir zunächst eine *Embedding Layer*. \n",
    "\n",
    "# Word Embeddings\n",
    "\n",
    "Mittlerweile werden diese One-Hot kodierten Vektoren nicht mehr direkt als Input verwendet. Bevor sie in das Netz eingespeist werden, wird eine Embedding Layer verwendet. Diese ersetzt die One-Hot-codierten Vektoren durch zunächst zufällige Zahlen. Um besser zu verstehen, was gemeint ist, schauen wir uns zunächst eine Embedding Layer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af505f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "embedding_layer=np.random.rand(7,4)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46a7ce",
   "metadata": {},
   "source": [
    "Eine Embedding Layer besteht aus einer einzigen Weight Matrix. Diesen enthält zufällige Zahlen. Die Anzahl der Zeilen entspricht genau der Anzahl der verschiedenen Token in unserem Wörterbuch. \n",
    "Eine Embedding Layer tauscht, einfach den Vektor `[1,0,0,0,0,0,0]` mit der ersten Reihe aus der `embedding_layer` aus. Welcher `embedding_layer[0,:]= [0.19151945, 0.62210877, 0.43772774, 0.78535858]` ist.\n",
    "\n",
    "Um das zu erreichen, müssen wir einfach die One-Hot kodierten Smiles mit der Embedding Layer multiplizieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b69630",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "token_embeddings = np.matmul(onehot_tokens,embedding_layer)\n",
    "print(token_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eab5d2",
   "metadata": {},
   "source": [
    "Sie können die Embeddings des ersten Smiles hier oben sehen.\n",
    "Unten sehen Sie die erste Zeile des One-Hot kodierten Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_tokens[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ea152",
   "metadata": {},
   "source": [
    "Wenn Sie sich jetzt in der Weight Matrix der `embedding_layer` die dritte Reihe (index `2`) anschauen, fällt auf, dass dieser Vektor genau dieselben Werte hat wie die erste Reihe in der `token_embeddings` Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8dc700",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663a9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_embeddings[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3c957",
   "metadata": {},
   "source": [
    "Einfacher erklärt: \n",
    "Eine Embedding Layer wandelt One-Hot kodierte Vektoren in Vektoren mit zufälligen Weights um. \n",
    "\n",
    "*Aber warum wird das gemacht?\n",
    "\n",
    "Ein Vorteil ist, dass Texte oder sogar Smiles in den meisten Fällen aus mehr als nur 7 Symbolen oder Wörtern bestehen. Würden wir zum Beispiel alle Wörter kodieren, die in einem Dokument vorkommen, würden diese Vektoren sehr lang werden. Durch die \"Embedding\" der Vektoren können wir zunächst die Größe dieser Inputvektoren verringern.\n",
    "\n",
    "Noch wichtiger ist, dass die Weights in der Embedding Layer erlernt werden können. Das bedeutet, dass diese Weights während der Backpropagation geupdatet werden.\n",
    "So passen sich die Embeddings während des Trainings an. Das ist praktisch, denn man erwartet, dass ähnliche Wörter nach dem Training ähnliche Embeddings erhalten. Zum Beispiel sind die Wörter LKW und Auto im Gebrauch ähnlicher als Auto und Strand. \n",
    "Wenn Auto und Lkw ähnliche Embeddings haben, d. h. durch ähnliche Vektoren beschrieben werden, dann können sie im Kontext des Satzes leichter verarbeitet werden.\n",
    "\n",
    "\n",
    "> Ein Auto fährt auf der Straße\n",
    "\n",
    "> Ein LKW fährt auf der Straße\n",
    "\n",
    "Beschreiben zwei sehr ähnlich Situation und wenn sich auch die numerischen Repräsentationen ähneln, fällt es dem Netzwerk leichter diese zu lernen.\n",
    "\n",
    "\n",
    "Im Falle von Smiles kann man argumentieren, dass die Rolle eines Stickstoffs in einem Molekül eher der eines Kohlenstoffs als der eines Fluors entspricht. Dies sollte sich insbesondere in den Embeddings widerspiegeln.\n",
    "\n",
    "\n",
    "# RNNs\n",
    "\n",
    "Wir haben jetzt die Smiles in das richtige Format umgewandelt. Wir müssen nur noch das `np.array` in einen Tensor umwandeln. Achten Sie darauf, dass wir zusätzlich die Funktion `.permute` verwenden. Die Funktion `.permute` wird verwendet, um Dimensionen eines Tensors zu tauschen. Das ist notwendig, da PyTorch bei RNNs erwartet, dass der Tensor wie folgt angeordnet ist:\n",
    "`[Länge des Smiles, Anzahl der Smiles, Embeddinggröße]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_tensor = torch.tensor(token_embeddings, dtype= torch.float).permute(1,0,2)\n",
    "token_embeddings_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d9bd1",
   "metadata": {},
   "source": [
    "Der Tensor `token_embeddings_tensor` hat die oben genannten Dimensionen. Jeder Smiles besteht aus `13` Token, unser Batch besteht aus `2` Smiles und jeder Token wird durch `4` Werte beschrieben. \n",
    "\n",
    "Wir können nun ein RNN definieren. Wie üblich gibt es auch im Modul `torch.nn` ein RNN.\n",
    "Auch hier muss man bei der Definition der Dimensionen vorsichtig sein. Die erste Dimension ist die Größe Inputvektoren, also die Embeddinggröße (`4`). Die zweite Dimension gibt an, wie viele Nodes wir in der Hidden Layer haben wollen. Damit wird auch festgelegt, wie groß die Vektoren des Hidden States sein sollen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "rnn = nn.RNN(4,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50365c7d",
   "metadata": {},
   "source": [
    "Sie können jetzt einfach den `token_embeddings_tensor` durch das `rnn` führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657190f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_rnn = rnn(token_embeddings_tensor)\n",
    "len(output_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622cfe87",
   "metadata": {},
   "source": [
    "Der Output des RNN (`output_rnn`) ist eine Liste mit der Länge zwei.\n",
    "Wir schauen uns zunächst das erste Objekt des Outputs an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1154e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(output_rnn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e415d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_rnn[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8af006",
   "metadata": {},
   "source": [
    "Der Output `output_rnn[0]` hat die Dimensionen `[13, 2, 10]`. Das einzige, was sich im Vergleich zum Input geändert hat, ist die letzte Dimension. Statt der Dimension `4` ist es jetzt `10`. \n",
    "\n",
    "Tatsächlich enthält der erste Teil des RNN Outputs die Hidden States jedes Symbols im Smiles.\n",
    "\n",
    "Denken Sie an das GIF zurück:\n",
    "\n",
    "<div align=\"center\">\n",
    "<img  align=\"center\" src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "    \n",
    "*Quelle: Michael Phi - An illustrated Guide to Recurrent Neural Networks.*\n",
    "\n",
    "</div>\n",
    "    \n",
    "`output_rnn[0]` enthält $O1$ bis $O5$. Da unsere Sequenzen aber die Länge 13 haben, enthält `output_rnn[0]` 13 Hidden States.\n",
    "\n",
    "Aber was enthält `output_rnn[1]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76272748",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_rnn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91a55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_rnn[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7908f6",
   "metadata": {},
   "source": [
    "`output_rnn[1]` enthält NUR den letzten Hidden State. Im GIF ist das $O5$, bei uns wäre es $O13$. Dieser Hidden State beschreibt (theoretisch) die komplette Sequenz und ist daher besonders wichtig.\n",
    "\n",
    "Das `output_rnn[0][-1]== output_rnn[1][0]` kann man auch kontrollieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639f24b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(output_rnn[0][-1])\n",
    "output_rnn[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d4c05",
   "metadata": {},
   "source": [
    "\n",
    "Um genauer zu verstehen, was passiert, werden wir das PyTorch RNN selbst neu programmieren.\n",
    "\n",
    "\n",
    "Nehmen wir an, wir haben einen Satz `Satz = [\"Hallo\", \"Welt\"]`. Wir haben diesen als zwei Wörter in einer Liste gespeichert. \n",
    "\n",
    "Wir definieren auch zwei einfache lineare Layers.  Die eine mappt den Input von Embeddinggröße `4`  auf `10` Dimensionen. Die andere Layer mappt von `10` auf `10` DImensionen.\n",
    "\n",
    "Durch das erste Netzwerk schicken wir das erste Wort `satz[0]` und speichern den Hidden State in `output_1`.\n",
    "\n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 =rnn(satz[0])\n",
    "```\n",
    "Als Nächstes führen wir auch das zweite Wort „World“ durch das `lin_1`. Doch im Anschluss addieren wir auch den `lin_2(output_1)` dazu. \n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 = lin_1(satz[0])\n",
    "\n",
    "output_2 = lin_1(satz[1]) + lin_2(output_1)\n",
    "```\n",
    "\n",
    "Das heißt, der Hidden State `output_2` wird nicht alleine durch das Wort `\"World\"` bestimmt, sondern der Hidden State zuvor hat auch Einfluss. Tatsächlich fügen wir auch noch eine nicht-lineare Aktivierungsfunktion hinzu. In RNNs wird per Default eine Tanh-Funktion anstatt einer ReLU-Funktion benutzt.\n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 = lin_1(satz[0])\n",
    "\n",
    "output_2 = torch.tanh(lin_1(satz[1]) + lin_2(output_1))\n",
    "```\n",
    "\n",
    "Hätten wir noch ein drittes Wort im Satz (`satz[2]`), dann würde sich der Schritt wiederholen. Wir addieren diesmal, aber nicht `output_1`, sondern `output_2` hinzu:\n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\", \"Dude\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 = lin_1(satz[0])\n",
    "\n",
    "output_2 = torch.tanh(lin_1(satz[2]) + lin_2(output_1))\n",
    "\n",
    "output_3 = torch.tanh(lin_1(satz[3]) + lin_2(output_2))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Um dies zu kontrollieren, schreiben wir ein eigenes Programm dafür.\n",
    "Zuerst speichern wir die Weights der `rnn`. Diese können wir nun selbst verwenden.\n",
    "Denken Sie daran, dass `nn.Linear()` nichts anderes ausführt als: `torch.mm(X,W.t())+b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50167a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1=list(rnn.parameters())[0]\n",
    "w_2=list(rnn.parameters())[1]\n",
    "b_1=list(rnn.parameters())[2]\n",
    "b_2=list(rnn.parameters())[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60372fd0",
   "metadata": {},
   "source": [
    "Mit diesen Weights können Sie nun den Hidden State für das erste Symbol in der Smiles Sequenz berechnen (`lin_1`). Diese befinden sich in `token_embeddings_tensor[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activations_jetzt = torch.mm(token_embeddings_tensor[0],____)+____\n",
    "activations_jetzt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfc7c3",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "activations_jetzt = torch.mm(token_embeddings_tensor[0],w_1.t())+b_1\n",
    "activations_jetzt\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cc165",
   "metadata": {},
   "source": [
    "Als nächstes transformieren wir den Hidden State des vorherigen Tokens (`lin_2`). \n",
    "Allerdings befinden wir uns im Moment beim ersten Wort/Token. Wir haben also noch keinen Hidden States eines vorherigen Tokens. Dieser Teil wurde im bisherigen Text ausgelassen. Tatsächlich beginnen wir mit einem Hidden State, in dem alle Werte Null sind. `h0 = torch.zeros(2,10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2dc15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h0 = torch.zeros(2,10)\n",
    "\n",
    "activations_vorher = torch.mm(___,____)+____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752cd59",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "h0 = torch.zeros(2,10)\n",
    "\n",
    "activations_vorher = torch.mm(h0,w_2.t())+b_2\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e38a7",
   "metadata": {},
   "source": [
    "Im letzten Schritt werden die beiden Activations addiert und eine `torch.tanh` Aktivierungsfunktion angewandt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22abc20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.tanh(___________+_____________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ec875",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "torch.tanh(activations_jetzt+activations_vorher)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30efabb2",
   "metadata": {},
   "source": [
    "Dies ist der Hidden State für den erste Token des Smilea.\n",
    "Wir können diesen auch mit dem Hidden State vom`nn.RNN`  vergleichen und sehen, dass diese identisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d03f84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_rnn[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321f929",
   "metadata": {},
   "source": [
    "Wir wollen die Hidden States nicht nur für den ersten Token berechnen, sondern für alle Tokens im Smiles. Daher benötigen wir einen `for-loop`. \n",
    "\n",
    "Zuerst initialisieren wir den ersten Hidden States mit Nullen. Und dann schreiben wir einen `for-loop`, der alle 13 Tokens durchläuft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(2,10)\n",
    "for i in range(max_smiles_length):\n",
    "    activations_jetzt =  # achten Sie bei der Berechnung darauf immer das i Element aus den Input auszuwählen\n",
    "    activations_vorher = \n",
    "    h0 = torch.tanh(activations_jetzt+activations_vorher) # <-- Der output wird als h0 gespeichert, \n",
    "h0                                                        #     um ihn in der nächsten Iteration als neues h0\n",
    "                                                          #     zuverwenden              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2617ce",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "h0 = torch.zeros(2,10)\n",
    "for i in range(max_smiles_length):\n",
    "    activations_jetzt = torch.mm(token_embeddings_tensor[i],w_1.t())+b_1\n",
    "    activations_vorher = torch.mm(h0,w_2.t())+b_2\n",
    "    h0 = torch.tanh(activations_jetzt+activations_vorher) \n",
    "h0                                                     \n",
    "```                                                          \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab8db7",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b></b></summary>\n",
    "\n",
    "```python\n",
    "h0 = torch.zeros(2,10)\n",
    "for i in range(max_smiles_length):\n",
    "    activations_jetzt = torch.mm(token_embeddings_tensor[i],w_1.t())+b_1\n",
    "    activations_vorher = torch.mm(h0,w_2.t())+b_2\n",
    "    h0 = torch.tanh(activations_jetzt+activations_vorher) \n",
    "h0                                                     \n",
    "```                                                          \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52917b",
   "metadata": {},
   "source": [
    "`h0` enthält nun den finalen Hidden State. Auch hier können wir überprüfen, ob unser Ergebnis mit dem von PyTorch `nn.RNN` identisch ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c841036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_rnn[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a849c",
   "metadata": {},
   "source": [
    "Natürlich ist es einfacher, die vorgeschriebene Funktion von PyTorch zu verwenden. \n",
    "Aber sie selbst zu programmieren sollte Ihnen helfen, besser zu verstehen, was genau in einem RNN passiert.\n",
    "\n",
    "Außerdem veranschaulicht der Code die größte Schwäche von RNNs: der `for-loop`.\n",
    "Wir können einen Satz/Smiles nicht auf einmal durch das Netzwerk führen. \n",
    "Jedes Wort/Symbol muss eines nach dem anderen durch das Netzwerk gegeben werden. Das macht RNNs extrem langsam.\n",
    "\n",
    "\n",
    "# PyTorch RNN\n",
    "\n",
    "PyTorch bietet uns nicht nur RNNs, sondern auch `nn.Embedding` Layers. Das ist praktisch. Zum einen macht es die Backpropagation einfacher. Zusätzlich müssen wir nicht die \n",
    "One-Hot kodierten Vektoren berechnen. PyTorch nimmt als Input sofort die tokenisierten Smiles (`tokenized_smiles`) als Input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8b34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(7,4, padding_idx = dictionary[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be3f61",
   "metadata": {},
   "source": [
    "Hier haben wir eine `torch` Embedding Layer definiert. Sie nimmt als Input die Anzahl der verschiedenen Symbole/Token in unserem Datensatz. In unserem Fall wäre dies `7`. Der zweite Parameter gibt die Größe der Embeddingsvektoren an. Wir bleiben bei der Größe `4`. Als letztes können wir PyTorch mitteilen, welcher Token, d.h. welche Zahl für das Padding steht. PyTorch wird dann die Embeddings für diese Token auf Null setzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb(torch.tensor(tokenized_smiles)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641ab29",
   "metadata": {},
   "source": [
    "Der Output dieser Embedding Layer hat noch nicht das richtige Format. Wir müssen noch die Dimensionen des Tensors mit `Permute` ändern. \n",
    "Wir können all diese Schritte in ein `nn.Sequential()` Modul packen. \n",
    "\n",
    "*Im Pytorch `nn` Modul gibt es kein Permute, das wurde von uns so angepasst, dass es auch in `nn.Sequential` funktioniert. Deshalb brauchen wir auch kein \"nn.\" vor dem Permute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dca082",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Embedding(7,4, padding_idx = dictionary[\"<pad>\"]),\n",
    "                     Permute(1,0,2),\n",
    "                     nn.RNN(4,10))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e198503",
   "metadata": {},
   "source": [
    "Die `tokenized_smiles` können nun durch das `model` geführt werden. Mit `[1][0,:,:]` werden die finalen Hidden States im richtigen Format extrahiert. Wir können diese direkt in eine lineare Layer einfügen. Da wir den Output mit `[1][0,:,:]` indizieren müssen, können wir die linearen Layers nicht direkt in demselben `nn.Sequential()`-Modell verwenden. Wir brauchen ein zweites Modell, das `output_rnn` als Input nimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda59427",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_rnn= model(torch.tensor(tokenized_smiles))[1][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ll = nn.Sequential(nn.Linear(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980edb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ll(output_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dcc187",
   "metadata": {},
   "source": [
    "Es gibt noch ein Problem mit dem `nn.RNN`. Im GIF kann man deutlich erkennen, dass die ersten Wörter im Satz immer weniger Einfluss haben, je länger der Satz wird. Dies kann ein Problem werden, wenn Sätze oder Smiles besonders lang werden. Vor allem, wenn Nebensätze oder im Falle von Smiles zusätzliche Branches in den `string` eingefügt werden, kann es passieren, dass der Anfang des Satzes oder desSmiles vom Netzwerk \"vergessen\" wird bzw. verloren geht.\n",
    "\n",
    "Aus diesem Grund werden in der Regel komplexere RNN-Layers verwendet. Dadurch können die Netze Informationen über längere `strings` halten.\n",
    "\n",
    "Eine beliebte Alternative ist die Gated Recurrent Unit (GRU). Das Kombinieren von Hidden States ist viel komplexer als bei \"Vanilla RNNs\", aber in PyTorch kann `nn.RNN` leicht durch `nn.GRU` ersetzt werden. Nichts muss am Rest des Netzwerkes geändert werden.\n",
    "\n",
    "<div align=\"center\">\n",
    "    \n",
    "RNN   |GRU\n",
    "------|--------\n",
    "<img align=\"center\" src=\"https://miro.medium.com/max/332/0*eRJCRsikdGGu8ffA.png\" width=\"200\"/> |<img src=\"https://miro.medium.com/max/700/1*RiOzdOVaaeKrUotY7-1a2A.png\" width=\"300\"/> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d90e7a",
   "metadata": {},
   "source": [
    "# Übungsaufgabe:\n",
    "\n",
    "In der Übungsaufgabe werden wir uns einen neuen Datensatz ansehen. Der Datensatz Blut-Hirn-Schranken-Penetration (BBBP) erfasst für 2000 Moleküle, ob sie durch die Blut-Hirn-Schranke diffundieren können.\n",
    "\n",
    "Die meisten Medikamente und Neurotransmitter können die Blut-Hirn-Schranke nicht passieren. Dies ist jedoch wichtig für Medikamente, die im zentralen Nervensystem wirken sollen. Daher ist eine genaue Vorhersage dieser Eigenschaften von großem Interesse.\n",
    "Der Originaldatensatz wurde 2012 veröffentlicht. Wir verwenden jedoch einen leicht modifizierten Datensatz. Hier wurden alle Informationen zur Stereochemie aus den Smiles bereits entfernt. Außerdem enthält der Datensatz nur Smiles, die aus weniger als 75 Tokens bestehen.\n",
    "> Martins, Ines Filipa, et al. “A Bayesian approach to in silico blood-brain barrier penetration modeling.” Journal of Chemical Information and Modeling 52.6 (2012): 1686-1697.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79a860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from os.path import exists\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install rdkit==2022.3.4\n",
    "    if exists(\"utils.py\") == False:\n",
    "        !wget https://raw.githubusercontent.com/kochgroup/intro_pharma_ai/main/utils/utils.py\n",
    "    %run utils.py\n",
    "else:\n",
    "    %run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6fa39",
   "metadata": {},
   "source": [
    "Sie könnnen zunächst den Datensatz einlesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff22b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bbbp = pd.read_csv(\"https://uni-muenster.sciebo.de/s/RrwUmm9mEE8wF46/download\")\n",
    "data_bbbp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b2d3e",
   "metadata": {},
   "source": [
    "Die `smiles` werden zusammen mit dem `target` angegeben. Eine `1` bedeutet, dass diese Moleküle durch die BBB diffundieren können. In der folgenden Zelle berechnen wir den Prozentsatz der Moleküle, die diese Eigenschaft im Datensatz haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a56f80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.sum(data_bbbp.target)/data_bbbp.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83275f43",
   "metadata": {},
   "source": [
    "Wegen des großen Ungleichgewichtes bietet sich als Metrik vor allem der ROC-AUC an.\n",
    "Doch bevor wir uns dem Training zuwenden können, müssen wir erst die Daten aufbereiten.\n",
    "Erstellen Sie zunächst einen `dictionary`, der allen Symbolen in den `smiles` Zahlen zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44644c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = create_dict(data_bbbp.smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f2a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3273b8",
   "metadata": {},
   "source": [
    "Mit diesem Dictionary, konvertieren Sie nun die eigentlichen Symbole der Smiles zu Zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0cb09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_smiles = tokenize(data_bbbp.smiles,dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ef5e1",
   "metadata": {},
   "source": [
    "Das Problem ist, wie auch schon im Beispiel, dass die Moleküle und damit die `smiles` unterschiedlich lang sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8785c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length_ll = np.array([len(x) for x in tokenized_smiles])\n",
    "length_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e5343",
   "metadata": {},
   "source": [
    "Sie müssen deswegen erst alle `tokenized_smiles` auf die gleiche Länge bringen. Und zwar auf die des längsten Smiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561303d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_length = max(length_ll)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f6f30",
   "metadata": {},
   "source": [
    "Zu allen Smiles, die aus weniger als 74 Tokens bestehen, fügen wir zusätzliche Tokens hinzu, bis sie 74 Tokens lang sind.\n",
    "Der hinzugefügte Token ist `<pad>`. Wir weisen ihm den Wert `len(dictionary)` zu, da dieser die nächste unbenutzte Zahl ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dictionary))\n",
    "dictionary[\"<pad>\"]= len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e8b6e",
   "metadata": {},
   "source": [
    "Der folgende Code hängt diesen Paddingtoken an alle Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5392ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tok_smi in enumerate(tokenized_smiles):\n",
    "    tokenized_smiles[i] = tok_smi+ [dictionary[\"<pad>\"]]*(max_length - length_ll[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_ll = [len(x) for x in tokenized_smiles]\n",
    "length_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac61b2",
   "metadata": {},
   "source": [
    "Nun sind alle `tokenized_smiles` gleich lang und im richtigen Format. Sie müssen aber zuvor wieder die Daten in Trainings- und Testdatensatz teilen. \n",
    "Dafür fügen wir die `tokenized_smiles` und Targets aus dem `data_bbbp` zusammen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd115684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bbbp_tokenized = np.hstack([np.array(tokenized_smiles), data_bbbp.iloc[:,1:2]])\n",
    "data_bbbp_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e74a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(data_bbbp_tokenized,test_size=0.2,train_size=0.8, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa7e24",
   "metadata": {},
   "source": [
    "Nun separieren Sie die Input und Outputs wieder von einander. Wichtig hierbei: Die `targets` befinden sich in der letzen Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(train[:,:-1], dtype=torch.long )\n",
    "train_y = torch.tensor(train[:,-1], dtype=torch.float)\n",
    "test_x = torch.tensor(test[:,:-1], dtype=torch.long)\n",
    "test_y = torch.tensor(test[:,-1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa661a",
   "metadata": {},
   "source": [
    "Erstellen Sie jetzt den Trainings Dataloader, damit wir mit Minibatches trainieren können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96278c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f89ddc",
   "metadata": {},
   "source": [
    "Jetzt definieren Sie das Model.\n",
    "Wir brauchen eine Embedding Layer, eine Permute Layer und ein RNN. Hierfür verwenden wir ein GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc00107",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1111)\n",
    "model =nn.Sequential(nn.Embedding(len(dictionary),32, padding_idx = dictionary[\"<pad>\"]),\n",
    "                     Permute(1,0,2),\n",
    "                     nn.GRU(32,64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d48e2",
   "metadata": {},
   "source": [
    "Außerdem benötigen Sie eine lineare Layer, die Vorhersagen auf Grundlage des Outputs des GRU trifft. \n",
    "Hierfür erstellen wir ein zweites Modell mit dem Namen `pred_ll`.\n",
    "\n",
    "Warum brauchen wir ein zweites Modell?\n",
    "\n",
    "Das liegt daran, dass alle RNNs in PyTorch mehr als einen Output haben. Einmal alle Hidden States und einmal die finalen Hidden States. Das `nn.Sequential` Netzwerk weiß in diesem Fall nicht, welchen Output vom RNN an die lineare Layer weitergegeben werden soll.\n",
    "\n",
    "Deshalb brauchen wir ein zweites Modell `pred_ll`. Hier verwenden wir Batchnorm und Dropout. Stellen Sie sicher, dass die Dimensionen von `BatchNorm1d` und `Linear` der Outputdimension des `GRU` entsprechen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1111)\n",
    "pred_ll = nn.Sequential(nn.BatchNorm1d(64),nn.Dropout(0.2),nn.Linear(64,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673b9e2",
   "metadata": {},
   "source": [
    "Auch definieren Sie wieder eine Lossfunktion und einen Optimizer. Denken Sie daran, dass wir eine Binary Klassifikation haben.\n",
    "Da wir zwei Netze haben, die wir gemeinsam updaten wollen, können wir die Parameter der beiden Netze in einer Liste zusammenfassen und sie dem Optimizer zur Verfügung stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_funktion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(pred_ll.parameters()), lr =0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6259062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    pred_ll.train()\n",
    "    for input_, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        rnn_output = model(input_)[1][0]\n",
    "        output = pred_ll(rnn_output).flatten()\n",
    "        \n",
    "        loss = loss_funktion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    pred_ll.eval()\n",
    "    \n",
    "    rnn_output = model(train_x)[1][0]    \n",
    "    output = pred_ll(rnn_output).flatten()\n",
    "    loss_train = loss_funktion(output, train_y)\n",
    "    auc_train = roc_auc_score(train_y.numpy(),torch.sigmoid(output).detach().clone().numpy())\n",
    "    \n",
    "    rnn_output = model(test_x)[1][0]    \n",
    "    output = pred_ll(rnn_output).flatten()\n",
    "    loss_test = loss_funktion(output, test_y)\n",
    "    auc_test = roc_auc_score(test_y.numpy(),torch.sigmoid(output).detach().clone().numpy())\n",
    "    \n",
    "    print(\"Training Loss: %.3f Training AUC: %.3f | Test Loss: %.3f Test AUC: %.3f\"\n",
    "        % (loss_train.item(), auc_train,loss_test.item(), auc_test ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0535564",
   "metadata": {},
   "source": [
    "Sie können sehen, dass Sie mit einem RNN genaue Vorhersagen machen können. In der Realität funktionieren oft ECFP und klassische neuronale Netze jedoch besser. Insbesondere bei kleinen Datensätzen, da sie nicht so komplex sind. \n",
    "\n",
    "Zuletzt betrachten wir die gelernten Embeddings. Hierfür speichern wir die Weightmatrix der Embeddings Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf9b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_weights = list(model[0].parameters())[0].detach().clone().numpy()\n",
    "embedding_weights.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378cdb7",
   "metadata": {},
   "source": [
    "Eine Möglichkeit die Embeddings zu analysieren, ist die Ähnlichkeit verschiedener Token über die `cosine_similarity` vergleichen. Tokens mit ähnlicher Funktion sollten ähnliche Embeddings haben.\n",
    "\n",
    "Als Beispiel berechnen wir die Ähnlichkeit der Embeddings von einem Stickstoff in einem aromatischen Ring (`n`).\n",
    "Dafür finden wir im Dictionary welche Zahl zu `\"n\"` gehört, und damit auch den Index der Reihe in der Embedding Matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e61b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_n = dictionary[\"n\"]\n",
    "dictionary[\"n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85fab4",
   "metadata": {},
   "source": [
    "Wir berechnen die Similarity von dieser Embedding zu allen andere Embeddings. Im Anschluß wird ein Barchart erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322387ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_N = cosine_similarity(embedding_weights[idx_n:idx_n+1,:],embedding_weights)[0]\n",
    "labels = [x for x in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values=pd.DataFrame({\"symbol\": labels, \"similarity\":similarity_N}).sort_values(\"similarity\", ascending =False)\n",
    "sorted_values.plot.bar(\"symbol\", \"similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc400e",
   "metadata": {},
   "source": [
    "Das Problem bei einem so kleinen Datensatz ist, dass die Embeddings extrem vom Datensatz abhängig sind. Dennoch lassen sich allgemeine Trends erkennen. `n` ist den aromatischen Atomen \"o\" oder \"c\" ähnlicher als den Atomen außerhalb eines aromatischen Rings `C`,`N` und `O`. Die genauen Embeddings können jedoch von Training zu Training extrem variieren.\n",
    "\n",
    "Sie können auch andere Symbole vergleichen, indem Sie hier nachsehen welcher Wert einenm bestimmten Token zugeordnet ist:\n",
    "\n",
    "`idx_n = dictionary[\"n\"]`\n",
    "\n",
    "Wählen Sie ein anderes Symbol."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
