{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft\n",
    "\n",
    "Chemical tasks in this or a second notebook?\n",
    "\n",
    "## Structure\n",
    "\n",
    "- Introduction\n",
    "- \"Attention Is All You Need\"\n",
    "- Encoder Decoder Structure\n",
    "- When to use Transformers (Sequence modeling)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "---\n",
    "### In this lesson you'll learn:\n",
    "\n",
    "- how the attention mechanism of transformers works.\n",
    "- why Transformers are so powerful.\n",
    "- how to build a transformer model for a simple task.\n",
    "---\n",
    "\n",
    "\n",
    "The introduction of the transformer architecture was one of the most important leaps forward in AI development. It powers large language models (LLMs) such as ChatGPT (**G**enerative **P**retrained ***T****ransformer*) and AlphaFold. In moder natural language processing (NLP) transformer models have replaced even complicated RNNs with LSTM- or GRU-layers. One large advantage of transformers is that they are able to read entire sequences at once instead of token by token, making training a lot faster. But how do transformers work? The title of the paper (cited > 100000 times) hints (or loudly screams) at the core mechanism:\n",
    "\n",
    "## \"Attention is all you need\"\n",
    "\n",
    "**TODO**: Describe attention here.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
