{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978f8a26",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "\n",
    "#### I did my best to minimize the training time. I had saved a model that was trained already. However, the server does not play along. Therefore it is best to just do something else for an hour when training. You don't have to train 100 epochs, you can end the training early via Kernel > Interrupt Kernel.\n",
    "---\n",
    "**Learning Objectives**\n",
    "- You understand the concept of an autoencoder\n",
    "- You understand the meaning of `<sos>`/`<eos>` tokens \n",
    "- You understand how an RNN can generate Smiles\n",
    "- You can also define a network as a PyTorch class\n",
    "---\n",
    "\n",
    "In today's notebook we will deal with the so called **autoencoders**.\n",
    "Autoencoders are mostly trained through selfsupervised training.\n",
    "As a reminder, selfsupervised training refers to training neural networks where input and output are identical. So the goal is to recover the input. \n",
    "\n",
    "But what is the added value of a network that only recovers the input?\n",
    "In fact, we are not necessarily interested in the output of an autoencoder. Rather, we are interested in what happens in the middle of the network. \n",
    "This is because the real goal of autoencoders is to compress the data, that is, to represent it as effectively as possible.\n",
    "\n",
    "The example image shows an autoencoder for images:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/b1786e74e233ac21f503f59d03f6af19a3699024/2-Figure1-1.png\" >\n",
    "\n",
    "*Yifei Zhang - A Better Autoencoder for Image: Convolutional Autoencoder* **2018**\n",
    "\n",
    "\n",
    "An autoencoder consists of two networks, an **encoder** and a **decoder**. The output of the encoder is used as input to the decoder. The encoder should learn to represent the data as effectively as possible in a low-dimensional space (latent space). This representation is usually simply a vector, also known as a **latent vector**. The decoder is trained to recover the original input using this latent vector. \n",
    "\n",
    "We can decide for ourselves how large the latent vector should be. Usually, a particularly small size is chosen to ensure greater compression.\n",
    "After successful training, the *latent vector* should contain enough information for the decoder to reconstruct the complete image, despite its small size. This means that this vector is sufficiently informative to describe the complete image. Actual applications go beyond simple reconstruction.\n",
    "\n",
    "For example, autoencoders are used to improve the quality of images. For this purpose, low-resolution images are used as input, and the output is the same image in its regular (higher) resolution. In this way, networks are trained that can later sharpen low-resolution images. \n",
    "\n",
    "\n",
    "<img src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60bcd0b7b750bae1a953d61d_autoencoder.png\" width =\"400px\">\n",
    "\n",
    "*Hmrishav Bandyopadhyay - An Introduction to Autoencoders: Everything You Need to Know* **2021**\n",
    "\n",
    "\n",
    "Autoencoders exist not only for images, but also for text. RNNs are used for this purpose. \n",
    "In the last notebook we already discussed that the last hidden state of an RNN is a summary of the whole input sequence. In the example the hidden state $O_5$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "\n",
    "*Michael Phi - An illustrated Guide to Recurrent Neural Networks*\n",
    "\n",
    "\n",
    "The output $O_5$ can already be understood as a projection of the entire sentence into the latent space. The hidden state $O5$ is thus the latent vector describing our sequence. Accordingly, the network that generated this vector is our encoder. So, all that is missing for our autoencoder is the decoder that can recover the original sequence from the latent vector. We will discuss how this works exactly using an example with smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import RDLogger  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "RDLogger.DisableLog('rdApp.*')      \n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2d9e1",
   "metadata": {},
   "source": [
    "This week we are using a dataset from the company Enamine. Namely, the [High Fidelity Fragment Library](https://enamine.net/compound-libraries/fragment-libraries/high-fidelity-library). This dataset consists of fragments that are particularly well suited for the MedChem field due to their physicochemical properties. It is particularly important for this example the the molecules are not too large. It is difficult to generate a valid smiles from a latent vector. The longer the smiles get, the more complex the task becomes for the network.\n",
    "\n",
    "This week the molecules are also available in a different file format. In the `.sdf` format the molecules are stored with more detail. For example, information about the conformation can be stored here. \n",
    "\n",
    "```\n",
    "\n",
    "  Mrv0541 07182119162D          \n",
    "\n",
    " 12 12  0  0  0  0            999 V2000\n",
    "    0.7145    2.0625    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145    1.2375    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289    0.8250    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289   -0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    2.1434   -0.4125    0.0000 F   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145   -0.4125    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145   -1.2375    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289   -1.6500    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   -0.0000   -1.6500    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.0000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   -0.7145   -0.4125    0.0000 F   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.0000    0.8250    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "  1  2  1  0  0  0  0\n",
    "  2  3  4  0  0  0  0\n",
    "  3  4  4  0  0  0  0\n",
    "  4  5  1  0  0  0  0\n",
    "  4  6  4  0  0  0  0\n",
    "  6  7  1  0  0  0  0\n",
    "  7  8  2  0  0  0  0\n",
    "  7  9  1  0  0  0  0\n",
    "  6 10  4  0  0  0  0\n",
    " 10 11  1  0  0  0  0\n",
    " 10 12  4  0  0  0  0\n",
    "  2 12  4  0  0  0  0\n",
    "M  END\n",
    ">  <Catalog ID>\n",
    "Z1255462241\n",
    "\n",
    ">  <PlateID>\n",
    "1225133-R3-01\n",
    "\n",
    ">  <Well>\n",
    "A02\n",
    "\n",
    ">  <MW (desalted)>\n",
    "172.129\n",
    "\n",
    ">  <CLogP>\n",
    "2.082\n",
    "\n",
    ">  <HBD>\n",
    "1\n",
    "\n",
    ">  <TPSA>\n",
    "37.300\n",
    "\n",
    ">  <RotBonds>\n",
    "1\n",
    "\n",
    "```\n",
    "You can also see additional information like TPSA or LogP can be saved in the same file.\n",
    "\n",
    "To read such a `.sdf` file into Python we need a so called `MolSupplier` from `rdkit`. A supplier establishes the connection between our files and Python. With a `for-loop` the smiles can be generated from the SDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppl = Chem.SDMolSupplier(\"../data/high_fidelity/Enamine_High_Fidelity_Fragment_Library_plated_1920cmds_20210718.sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "for mol in suppl:\n",
    "    smiles.append(Chem.MolToSmiles(mol)) \n",
    "smiles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfa9c",
   "metadata": {},
   "source": [
    "As you can see, this is another way to read in molecules into python.\n",
    "\n",
    "We can display the structures once to get a better feel for the nature of the fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1984e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MolsToGridImage([Chem.MolFromSmiles(x)for x in smiles[:9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb44b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619c39e",
   "metadata": {},
   "source": [
    "In total, we have 1920 molecules in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af29b3",
   "metadata": {},
   "source": [
    "When you look closely at the Smiles, do you notice anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70b608",
   "metadata": {},
   "source": [
    "One problem is that the stereo information is still included in the smiles. For example the `@` symbol. Another problem is the `.`. This marks the beginning of another molecule. In our case, however, these are actually only `Cl` atoms that are contained in some smiles. \n",
    "For example the molecules 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642e7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(smiles[26])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547f368",
   "metadata": {},
   "source": [
    "We can remove the stereo information as well as the \"extra\" molecules with string manipulations.\n",
    "\n",
    "`string.replace(\"@\", \"\")`\n",
    "\n",
    "searches the `string` for the character `@` and if it finds one, they are replaced by `\"\"`, so simply removed.\n",
    "\n",
    "`string.split(\".\")`\n",
    "\n",
    "splits the `string` at each `\".\"`. The function outputs the individual substrings as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Schoko.l@de\".replace(\"@\", \"\").split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07972f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_molecules = []\n",
    "for smile in smiles:\n",
    "    smile = smile.replace(\"@\", \"\")\n",
    "    smile = smile.replace(\"\\\\\", \"\")\n",
    "    sub_molecules.append(smile.split(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e7da1",
   "metadata": {},
   "source": [
    "In the next step, we just have to go through the molecule lists. If a smiles consists of several molecules, we simply select the largest molecule as the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97a07d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_smiles =[]\n",
    "for mol_list in sub_molecules:\n",
    "    filtered_smiles.append(mol_list[np.argmax([len(x) for x in mol_list])])\n",
    "    \n",
    "Chem.MolFromSmiles(filtered_smiles[26])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b429d79",
   "metadata": {},
   "source": [
    "The 27 molecule now no longer has the additional `HCl`s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bac998",
   "metadata": {},
   "source": [
    "The smiles are now \"clean\" and we can start preparing them for the RNN. So create a dictionary and replace the smiles with tokens. For this we again use the `creat_dict` function to create a dictionery for our data. But this time we also use the parameter `add_tokens = True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047333c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = create_dict(filtered_smiles, add_tokens =True)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4917b",
   "metadata": {},
   "source": [
    "Three new tokens were added to the dictionary, that did not appear in the smiles.\n",
    "\n",
    "- You already know `<pad>`. It is used to bring all smiles to the same length.\n",
    "\n",
    "- `<sos>` is a token that announces the start of a smiles. \"start of sentence\". This token is set **before** each smiles.\n",
    "\n",
    "- `<eos>` indicates the end of the smiles. After the actual smiles is finished, the `<eos>` token follows, and then the padding token are added (if needed).\n",
    "\n",
    "So all our smiles should look like this:\n",
    "\n",
    "```python\n",
    "\"<sos>OCc1ccc2occc2c1<eos><pad><pad>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bb0b0",
   "metadata": {},
   "source": [
    "\n",
    "Why is this necessary? Why are these special tokens needed?\n",
    "\n",
    "It's due to how a decoder works in an RNN. \n",
    "\n",
    "Here again is a reminder, this is what our model looks like:\n",
    "\n",
    "<img src=\"Img/rnn/auto_1.png\" width =\"400px\">\n",
    "\n",
    "We wrote the encoder last week, now we just need to focus on the decoder.\n",
    "The basic idea of a decoder RNN is that the SMILES are generated one token at a time.\n",
    "\n",
    "Example:\n",
    "\n",
    "The decoder receives the latent vector from the encoder:\n",
    "Based on the latent vector it generates a `C`. Now the decoder can generate another `C` using the latent vector and the information on the already generated `C`. Our current smiles is now `CC`. This step is repeated again, with the knowledge of the latent vector and the already two generated tokens `CC`.\n",
    "Now the decoder can generate a `=`: `CC=` etc...\n",
    "Theoretically, this could go on indefinitely. To prevent this the `<eos>` token is ontroduced. This token allows the network to terminate the smiles generation when it \"thinks\" it is complete.\n",
    "\n",
    "In the following, it becomes a bit more theoretical:\n",
    "To understand it in more detail, let's briefly review how an RNN works.\n",
    "\n",
    "An RNN always has two inputs. One is the regular input, i.e. the current token (smile symbol) for which a prediction has to be made.\n",
    "In addition, a hidden state is taken from the previous step. The output of the RNN for the previous token.\n",
    "\n",
    "Through the encoder, we already get the latent vector that will be our initial hidden state for the decoder. \n",
    "\n",
    "<img src=\"Img/rnn/auto_3.png\" width =\"400px\">\n",
    "\n",
    "But what is our initial input?\n",
    "\n",
    "<img src=\"Img/rnn/auto_4.png\" width =\"400px\">\n",
    "\n",
    "The problem is, if we use the actual first token of the original smile as the first token for the decoder, it's relatively easy to predict it correctly. Therefore, we the token `<sos>` as the first input for the decoder. This token does not contain any information about the input miles. Hence the first tokenfirst token is predicted based only on the hidden state/latent vector. It is also important to note that the output of the RNN (the new hidden state) first passes through a linear layer, which then predicts the correct token.\n",
    "\n",
    "<img src=\"Img\\rnn\\auto_6.png\" width =\"400px\">\n",
    "\n",
    "In the next step, the new hidden state replaces the latent vector as the input for the next step. Also, instead of using a token of the original smile as input, the token predicted in the previous step by the decoder is used. \n",
    "So, if the decoder makes a mistake at the beginning, it continues to decode with that mistake in the generated Smiles.\n",
    "<img src=\"Img\\rnn\\auto_7.png\" width =\"400px\">\n",
    "\n",
    "This is repeated until the length of the longest smile in our dataset is reached. Of course, most smiles are not that long, so the network e can use the `<eos>` token. This allows the smiles to be terminated before the maximum length is reached. \n",
    "<img src=\"Img/rnn/auto_8.png\" width =\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760abc3c",
   "metadata": {},
   "source": [
    "If we use ` (..., add_tokens=True)` in the `tokenize` function, `<sos>` and `<eos>` will be automatically added to each smile. The `0` represents in the `dictionary` the `<sos>` token and the `1` the `<eos>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles = tokenize(filtered_smiles,dictionary, add_tokens =True)\n",
    "tokenized_smiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157fd4b",
   "metadata": {},
   "source": [
    "The smiles have still all different lengths. We first calculate the number of tokens in each smile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba76b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = np.array([len(x) for x in tokenized_smiles])\n",
    "max_length=max(token_lengths)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d941b",
   "metadata": {},
   "source": [
    "We can also display the number of tokens with a histogram. The problem is, the more tokens a smiles has, the more difficult it is for the decoder to recover the complete smile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b22d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(token_lengths, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df0d1f",
   "metadata": {},
   "source": [
    "To reduce the impact of smiles length, we could throw out all molecules from the dataset that consist of more than 26 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(token_lengths>26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16c132",
   "metadata": {},
   "source": [
    "That are exactly 291 molecules. That's not ideal, of course, but it will help us train the network. Especially with so little data, it is difficult to train an autoencoder. Nevertheless, we remove these molecules from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40f8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_smiles=np.array(filtered_smiles)[token_lengths<=26].tolist()\n",
    "len(filtered_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c326e3a",
   "metadata": {},
   "source": [
    "With the reduced data, we create a new dictionary and tokenize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ef97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = create_dict(filtered_smiles, add_tokens =True)\n",
    "tokenized_smiles = tokenize(filtered_smiles,dictionary, add_tokens =True)\n",
    "tokenized_smiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = np.array([len(x) for x in tokenized_smiles])\n",
    "max_length=max(token_lengths)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decca5bc",
   "metadata": {},
   "source": [
    "All our smiles now consist of a maximum of 26 characters. In a last step we have to bring the smiles that do not consist of 26 tokens to the right length. For this we use the `<pad>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tok_smi in enumerate(tokenized_smiles):\n",
    "    tokenized_smiles[i] = tok_smi+ [dictionary[\"<pad>\"]]*(max_length - token_lengths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c6cde",
   "metadata": {},
   "source": [
    "In the last step we convert the lists of tokens into a `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09693c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles=torch.tensor(tokenized_smiles, dtype=torch.long)\n",
    "tokenized_smiles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c342b",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Today we will not use `nn.Sequential` to build our model. For simple architectures `nn.Sequential` is a good choice. However, it is not very flexible. \n",
    "Therefore, most networks will be written \"by hand\" in PyTorch.\n",
    "\n",
    "There are two processes that a network in PyTorch must always perform:\n",
    "\n",
    "1. initialize the necessary weights \n",
    "2. pass the input through the network\n",
    "\n",
    "The initialization at `nn.Sequential()` is done automatically when the model is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10,20), nn.ReLU(), nn.Dropout(0.2), nn.Linear(20,1))\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa79a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1a0ab",
   "metadata": {},
   "source": [
    "This is how we have defined our networks so far. Each layer is automatically created and the Weights randomly initialized.\n",
    "\n",
    "However, we can also define our own networks.\n",
    "To do this, we need to create a PyTorch class. Classes in Python are similar to functions. Except that classes can also contain properties and their own functions. We will not go into the exact functionalities of classes here.\n",
    "\n",
    "The only important thing is that we can also create classes that behave like PyTorch classes.\n",
    "To do this, we first write the following code:\n",
    "\n",
    "```python\n",
    "class simple_nn(nn.modules):\n",
    "```\n",
    "With this, we specify that the class `simple_nn` is a class that belongs to `nn.Module`. So like other layers or models in PyTorch, it should belong to `nn` or at least function similarly.\n",
    "\n",
    "Next comes the initialization:  \n",
    "\n",
    "```python\n",
    "class simple_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "```\n",
    "\n",
    "`def __init__(self,input_dim, hid_dim, out_dim, dropout):` is a function that is called when the net is initialized. So for example `model = simple_nn`. Will automatically execute what is written in the `__init__` function. It is important to specify a `self` as input, in addition to the dimensions, that determine the size of the network.\n",
    "\n",
    "`self` \"contains\" all the information that are stored for this class. Information stored in `self` can also be used beyond the function in which they were intially placed there. This should become clearer in a few minutes.\n",
    "\n",
    "`super().__init__()` is part of the code that is important for PyTorch classes. This part must not be missing in the initialization.\n",
    "\n",
    "Next, we can \"store\" our linear layers and dropout in `self`:\n",
    "\n",
    "```python\n",
    "class simple_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "```\n",
    "\n",
    "`self.ln1 = nn.Linear(input_dim, hid_dim)` allows us to select the first linear layer with `self.ln1` in other function of the Pytorch class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a67e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84193b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2 = simple_nn(input_dim=10, hid_dim= 20, out_dim=1, dropout=0.2)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59106e34",
   "metadata": {},
   "source": [
    "We can see that the network consists of the correct layers, but in the wrong order. Also the ReLU function is missing. This is not a big deal so far, because the function `__init__` is only supposed to initialize the model, i.e. only create the layers and their weights. ReLU has no weights and therefore does not need to be \"initialized\".\n",
    "\n",
    "Here is the proof that the network `model_2` now has random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4981a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(model_2.parameters())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f22545",
   "metadata": {},
   "source": [
    "We can try if the model can generate an output from an input (`fake_input` consists of random numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_input = (torch.rand(10))\n",
    "\n",
    "model(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358ba25",
   "metadata": {},
   "source": [
    "No problem for the `nn.Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75736a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_input = (torch.rand(10))\n",
    "\n",
    "model_2(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2818a",
   "metadata": {},
   "source": [
    "This error \n",
    "\n",
    "```python\n",
    "raise NotImplementedError\n",
    "```\n",
    "is printed. This indicates that we have not implemented this part of the model, i.e. we have not defined it in the class yet.\n",
    "\n",
    "So far `simple_nn` can only initialize the weights. But it does not yet know how to pass the inputs through the neural network. In `nn.Sequential` this is done automatically. The input is simply passed through the layers one after the other. The sequence is determined by the order of these layers at initialization. \n",
    "\n",
    "To make this work for our own class, we need another function called \n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "`forward` is, as the name implies, responsible for forward pass. It determines in what order input `x` is passed through the previously defined layers.\n",
    "It is also important to note that `self` is another input besides `x`. `self` contains all the information we have already defined in `__ìnit__`.\n",
    "\n",
    "```python\n",
    "class simple_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.ln2(x)\n",
    "        return output\n",
    "```\n",
    "\n",
    "\n",
    "Here we specify step by step what should happen to the original input. In the first step `x` is passed through the first linear layer. This was stored in `self.ln1`. Only for the activation function we don't need `self`, because it was not initialized.\n",
    "\n",
    "---\n",
    "**It is also important that we now cannot use**`nn.ReLU` **any more, but we must use** `.nn.functional.relu()`**.** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad426321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.ln2(x)\n",
    "        return output\n",
    "    \n",
    "model_2 = einfaches_nn(input_dim=10,hid_dim= 20, out_dim=1, dropout=0.2)\n",
    "model_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39badb3",
   "metadata": {},
   "source": [
    "Nothing has changed in the initialization, but we can now pass inputs through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7113cf5",
   "metadata": {},
   "source": [
    "Now we can design more complex networks that don't have just one input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c968a",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "Now back to our autoencoder.\n",
    "First we define the encoder.\n",
    "We have an `nn.Embedding` layer and an `nn.GRU` layer. The encoder is built exactly like the RNN in the last notebook, except that here we explicitly write the network ourselves.\n",
    "\n",
    "Take a look at the `forward` function. As input it takes a `input_seq`, which is a sequence of tokens. The output is the last `hidden` state of the network. This describes the complete smiles and is also our latent vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        outputs, hidden = self.rnn(embedded) \n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017de72c",
   "metadata": {},
   "source": [
    "## Decoder \n",
    "\n",
    "The decoder is already a bit more complex.  If you don't understand the complete code, that's fine. As long as you can follow the general concept.\n",
    "Again we have an `Embedding` Layer and a `GRU` Layer, additionally there is a Linear Layer. This layer determines which token to generate based on the hidden state.\n",
    "\n",
    "In the `forward` pass there are two inputs. Once the `input`, this is the last token, which was predicted. At the beginning this is the`<sos>` token. `hidden` is the hidden state of the `GRU` from the previous step.\n",
    "`forward` outputs both the `prediction`, the predicted token, and `hidden`, the new hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output[0])\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78160a22",
   "metadata": {},
   "source": [
    "Finally we merge both components in an `autoencoder`. As input this model takes a decoder and an encoder.  The autoencoder also has its own `forward` pass. First the input is passed through the encoder. The encoder provides us with the hidden state `hidden`. This hidden state is then used once at the beginning of the `for-loop` for the decoder. Also, we take the first column of `output_seq` as the first input to the decoder. This column consists of the `<sos>` tokens.\n",
    "\n",
    "Additionally, we introduce  teacher forcing. Teacher forcing is used during training to make it easier for the decoder to recover the full smiles. If the decoder suggests an incorrect token at the beginning of a smile, the decoder must continue computing with that incorrect token as input. This can be a problem especially at the beginning of the training, because many mistakes are made here. By using teacher forcing the predicted token is replaced by the correct token. Thus the decoder can continue to calculate with the correct token. Teacher forcing is  switched off during the evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        \n",
    "    def forward(self, input_seq, output_seq, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        # save parameters\n",
    "        batch_size = output_seq.shape[1]\n",
    "        trg_len = output_seq.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        \n",
    "        \n",
    "        # Actual Forward Pass\n",
    "        \n",
    "        # The encoder calculates the hidden state/latent vector\n",
    "        hidden = self.encoder(input_seq)\n",
    "        \n",
    "        # As initial input for the decoder we select the <sos> tokens\n",
    "        input = output_seq[0,:]\n",
    "        \n",
    "        # The for-loop is used to generate the tokens one after the other.\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            top1 = output.argmax(1) \n",
    "\n",
    "            input = output_seq[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c8ed2",
   "metadata": {},
   "source": [
    "As already said, it's okay if you don't understand every detail in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966af5d2",
   "metadata": {},
   "source": [
    "To create the autoencoder we first need to define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34add64c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "enc = Encoder(len(dictionary), 128, 256, 0.2)\n",
    "dec = Decoder(len(dictionary),128,256,0.2)\n",
    "model = Autoencoder(enc, dec)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b2133",
   "metadata": {},
   "source": [
    "You can clearly see the different components of the autoencoder.\n",
    "We also create a `DataLoader`. For $x$ and $y$ it uses same sequence, because we want to train an autoencoder which reconstructs $x$. We also store a sample batch `ex_in` and `ex_out`.\n",
    "\n",
    "Since we have so little data, we don\\`t use a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tokenized_smiles, tokenized_smiles)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "ex_in= ex_out = tokenized_smiles[:16,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d8fa3",
   "metadata": {},
   "source": [
    "We define our optimizer and our loss function. Here we can also specify that the index `2` should be ignored when calculating the loss. This is the index for the `<pad>` token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b2f2c",
   "metadata": {},
   "source": [
    "The last step is the training loop. This is a regular `for-loop`, but we use the transpose of the `input_seq` and the `output_seq`. This is because the functions of the netowrks merge more easily this way. \n",
    "\n",
    "In the training loop itself, the quality of the generated smiles is evaluated every five epochs. It is evaluated based on how many generated smiles are valid and how many of them are actually identical to the input.\n",
    "\n",
    "This is done by the function `evaluate()`, which was pre-written for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fac53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for input_seq, output_seq in train_loader:\n",
    "        optimizer.zero_grad()        \n",
    "        \n",
    "        input_seq = input_seq.t()\n",
    "        output_seq = output_seq.t()\n",
    "\n",
    "\n",
    "        output = model(input_seq, output_seq, 0.2)\n",
    "        \n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].reshape(-1, output_dim)\n",
    "        output_seq =  output_seq[1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output,  output_seq)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch%5==0):\n",
    "        valid, correct=evaluate(model, train_loader, dictionary)\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss /len(train_loader)} % Valid: {valid.round(2)} % Correct: {correct.round(2)} \")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss /len(train_loader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fca008",
   "metadata": {},
   "source": [
    "Now we can see how good our model really is. For the evaluation teacher forcing is turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model,train_loader, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06fcdcb",
   "metadata": {},
   "source": [
    "Our autoencoder actually generates valid smiles. Many of the generated smiles are actually identical to the input smiles.\n",
    "\n",
    "Autoencoders are difficult to train, especially for languages or Smiles. The grammar of Smiles has to be learned first. This actually requires much more data. Moreover, we use a very simple model. Nevertheless, we can take a closer look at the network.\n",
    "\n",
    "For example, we can look at the predictions for our `ex_in` batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0f177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(ex_in.t(), ex_out.t(), 0)\n",
    "pred_tokens =pred.argmax(2).t().detach().numpy()\n",
    "\n",
    "pred_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254adc7",
   "metadata": {},
   "source": [
    "For comparison, the original smiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b3736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_out[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd843bf7",
   "metadata": {},
   "source": [
    "The function `token_to_smiles` converts the tokens back to smiles:\n",
    "This is what the predicted smiles look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_smiles = tokens_to_smiles(pred_tokens,dictionary )\n",
    "true_smiles = tokens_to_smiles(ex_out.detach().numpy(), dictionary)\n",
    "pd.DataFrame({\"true\":true_smiles, \"pred\": pred_smiles })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19630902",
   "metadata": {},
   "source": [
    "In fact, most smiles are identical to the original. But there are also deviating smiles. The smiles with index 8 is not identical and is not even a valid Smiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48da8a",
   "metadata": {},
   "source": [
    "# Generate new molecules\n",
    "\n",
    "We have a decoder that can generate valid molecules from our hidden states/latent vectors. \n",
    "So far, we have obtained the latent vectors by passing known smiles through the encoder. But what's stopping us from generating random latent vectors and seeing what the decoder generates from them? Our hidden states/latent vectors have this size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors =  model.encoder(ex_in.t()).detach().numpy()\n",
    "latent_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e13f03",
   "metadata": {},
   "source": [
    "We can simply create an alternative latent `tensor`. We fill this one with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5489786)\n",
    "hidden = torch.randn(1,16,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab24ca",
   "metadata": {},
   "source": [
    "We use this instead of the original `tensor` as input for the decoder.\n",
    "The decoder should now try to generate new smiles from this random data. Since the hidden state was chosen randomly, the generated molecules shouldnot be part of our original data set. This is one example of de novo design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0563cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.zeros(26, 16, len(dictionary))\n",
    "input_ = ex_out.t()[0,:] #<- [\"<sos>\"] Tokens\n",
    "for t in range(1, 26):\n",
    "    output, hidden = model.decoder(input_, hidden)\n",
    "    outputs[t] = output\n",
    "    input_ = output.argmax(1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9de3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_tokens = outputs.argmax(2).t().detach().numpy()\n",
    "new_smiles = tokens_to_smiles(pred_tokens, dictionary)\n",
    "new_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f51e52",
   "metadata": {},
   "source": [
    "In fact, none of these molecules are included in our data set. This is mainly because they are not valid molecules. Except \"Cl\".\n",
    "The problem is mainly that the latent space, i.e. the total space that can be described by our latent vectors, is too large. It will be very difficult to find random numbers that give a valid molecule.\n",
    "\n",
    "To really generate molecules effectively using autoencoders, we need much more data. That way the grammar of smiles can be learned better. Also, so-called variational autoencoders (VAEs) are most commonly used. These \"force\" the latent space into a predefined space. If one then chooses random numbers within the same defined space, the probability that the generated smiles is a valid molecule is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62529bf",
   "metadata": {},
   "source": [
    "# Übungsaufgabe\n",
    "\n",
    "Today\\`s exercise is not about autoencoders. The task is to rewrite an `nn.Sequential` model into a working PyTorch class.\n",
    "\n",
    "The model looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import RDLogger  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "RDLogger.DisableLog('rdApp.*')      \n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6f7ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_1 =nn.Sequential(nn.Linear(20,100),\n",
    "              nn.BatchNorm1d(100),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(100,100),\n",
    "              nn.BatchNorm1d(100),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(100,10))\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d5884",
   "metadata": {},
   "source": [
    "Rewrite the model. Note that `nn.ReLU` does not work in `forward`. Please use `nn.functional.relu()`. It is also important to know that `__init__` can have as many input parameters as you want, for example you can write `__init__` like this:\n",
    "`__init__(self, input_dim, hid1_dim, hid2_dim, ________)` to initialize multiple hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4da2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class simple_nn(________):\n",
    "    def __init__(self, ___________________________________________):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = simple_nn(______________________________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7c204",
   "metadata": {},
   "source": [
    "Test if your model generates an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(213)\n",
    "test_data = torch.randn(100,20)\n",
    "\n",
    "model_2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25431735",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
